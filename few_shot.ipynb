{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "acc_function = MulticlassAccuracy(num_classes=102, average='micro').to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "SEED = 196\n",
    "np.random.seed(SEED)\n",
    "generator = torch.Generator().manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_transforms = v2.Compose([\n",
    "    v2.RandomRotation(30),\n",
    "    v2.RandomResizedCrop(224),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Assuming you want to keep the default transformations for testing/validation:\n",
    "default_transforms = v2.Compose([\n",
    "    models.VGG16_BN_Weights.IMAGENET1K_V1.transforms()\n",
    "])\n",
    "\n",
    "flowers_train = datasets.Flowers102(root='./data', split='train', download=True, transform=train_transforms)\n",
    "flowers_test = datasets.Flowers102(root='./data', split='test', download=True, transform=default_transforms)\n",
    "flowers_val = datasets.Flowers102(root='./data', split='val', download=True, transform=default_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(flowers_train, batch_size=batch_size, shuffle=True, generator=generator)\n",
    "    test_loader = torch.utils.data.DataLoader(flowers_test, batch_size=batch_size, shuffle=True, generator=generator)\n",
    "    val_loader = torch.utils.data.DataLoader(flowers_val, batch_size=batch_size, shuffle=True, generator=generator)\n",
    "    return train_loader, test_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping based on accuracy\n",
    "class AccuracyEarlyStopper:\n",
    "    def __init__(self, patience=5, min_delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.max_validation_accuracy = 0\n",
    "\n",
    "    def early_stop(self, validation_accuracy):\n",
    "        if validation_accuracy > (self.max_validation_accuracy + self.min_delta):\n",
    "            self.max_validation_accuracy = validation_accuracy\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader, loss_fn=loss_fn):\n",
    "    running_loss_value = 0\n",
    "    for images, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        running_loss_value += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return running_loss_value / len(dataloader)\n",
    "\n",
    "def test_eval(model, dataloader, loss_fn=loss_fn):\n",
    "    running_loss_value = 0\n",
    "    running_acc_value = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            acc = acc_function(outputs, labels)\n",
    "            running_loss_value += loss.item()\n",
    "            running_acc_value += acc.item()\n",
    "    running_acc_value /= len(dataloader)\n",
    "    running_loss_value /= len(dataloader)\n",
    "    return running_acc_value*100, running_loss_value\n",
    "\n",
    "def train_eval_test(model, train_dataloader, val_dataloader, test_dataloader, no_epochs=10):\n",
    "    es = AccuracyEarlyStopper()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_loss_arr, train_acc_arr, eval_loss_arr, eval_acc_arr, train_time = [], [], [], [], []\n",
    "    for i in range(no_epochs):\n",
    "        start = datetime.datetime.now()\n",
    "        train_loss = train(model, optimizer, train_dataloader)\n",
    "        end = datetime.datetime.now()\n",
    "        eval_acc, eval_loss = test_eval(model, val_dataloader)\n",
    "        time_taken = (end-start).total_seconds()\n",
    "        print(f'Epoch {i+1} Train Loss: {train_loss:>8f}, Eval Accuracy: {eval_acc:>0.2f}%, Eval Loss: {eval_loss:>8f}, Train Time: {time_taken:>0.2f}s')\n",
    "        train_loss_arr.append(train_loss)\n",
    "        eval_loss_arr.append(eval_loss)\n",
    "        eval_acc_arr.append(eval_acc)\n",
    "        train_time.append(time_taken)\n",
    "        if es.early_stop(eval_acc):\n",
    "            print('Early stopping activated')\n",
    "            break\n",
    "    test_acc, test_loss = test_eval(model, test_dataloader)\n",
    "    print(f\"Test Accuracy: {test_acc}, Test Loss: {test_loss}\")\n",
    "    return train_loss_arr, train_acc_arr, eval_loss_arr, eval_acc_arr, test_acc, test_loss, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_data_loader(dataset, subset_size, batch_size, generator):\n",
    "    # Create a random subset of indices\n",
    "    subset_indices = torch.randperm(len(dataset), generator=generator)[:subset_size].tolist()\n",
    "    \n",
    "    # Create a DataLoader for only the subset of data\n",
    "    subset_data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        sampler=torch.utils.data.SubsetRandomSampler(subset_indices, generator=generator)\n",
    "    )\n",
    "    \n",
    "    return subset_data_loader\n",
    "\n",
    "\n",
    "def few_shot_train_eval_test(model, train_dataset, val_dataloader, test_dataloader, few_shot_size, no_epochs=10):\n",
    "    # Get the subset DataLoader for few-shot learning\n",
    "    train_data_loader = get_subset_data_loader(train_dataset, few_shot_size, batch_size, generator)\n",
    "    \n",
    "    # Continue with the rest of your training code\n",
    "    return train_eval_test(model, train_data_loader, val_dataloader, test_dataloader, no_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader, test_data_loader, val_data_loader = get_data_loader(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply few-shot learning\n",
    "few_shot_size = 20  # For example, use 20 images per class for few-shot learning\n",
    "base_model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "base_model.fc = nn.Linear(512, 102)\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "# Fine-tune the pre-trained model with the few-shot subset\n",
    "few_shot_train_acc, few_shot_train_loss, few_shot_eval_loss, few_shot_eval_acc, few_shot_test_acc, few_shot_test_loss, few_shot_train_time = few_shot_train_eval_test(\n",
    "    base_model, \n",
    "    train_data_loader,  # Pass the train dataset directly\n",
    "    val_data_loader, \n",
    "    test_data_loader,\n",
    "    few_shot_size,  # Pass the few-shot size\n",
    "    no_epochs=no_epochs\n",
    ")\n",
    "\n",
    "# Now you can compare the results to see how well the model performs with few-shot learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
