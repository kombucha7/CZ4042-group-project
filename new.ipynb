{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.ops import deform_conv2d\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define your device at the beginning\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data Augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Assuming you want to keep the default transformations for testing/validation:\n",
    "default_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "flowers_train = datasets.Flowers102(root='./data', split='train', download=True, transform=train_transforms)\n",
    "flowers_test = datasets.Flowers102(root='./data', split='test', download=True, transform=default_transforms)\n",
    "flowers_val = datasets.Flowers102(root='./data', split='val', download=True, transform=default_transforms)\n",
    "\n",
    "def get_data_loader(batch_size):\n",
    "    train_loader = DataLoader(flowers_train, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(flowers_test, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(flowers_val, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, test_loader, val_loader\n",
    "\n",
    "# Define a function to replace the first conv layer of each block with deform_conv2d\n",
    "def insert_deformable_convs(resnet_model):\n",
    "    for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "        layer = getattr(resnet_model, layer_name)\n",
    "        for block in layer:\n",
    "            # Replace the conv1 in each BasicBlock\n",
    "            conv1 = block.conv1\n",
    "            out_channels = conv1.out_channels\n",
    "            in_channels = conv1.in_channels\n",
    "            kernel_size = conv1.kernel_size\n",
    "            stride = conv1.stride\n",
    "            padding = conv1.padding\n",
    "            block.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels * kernel_size[0] * kernel_size[1], \n",
    "                          kernel_size=kernel_size, stride=stride, padding=padding, groups=in_channels),\n",
    "                nn.BatchNorm2d(in_channels * kernel_size[0] * kernel_size[1]),\n",
    "                nn.ReLU(inplace=True),\n",
    "                deform_conv2d.DeformConv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                                           stride=stride, padding=padding)\n",
    "            )\n",
    "    return resnet_model\n",
    "\n",
    "# Early stopping based on accuracy\n",
    "class AccuracyEarlyStopper:\n",
    "    def __init__(self, patience=3, min_delta=0.5):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.max_validation_accuracy = 0\n",
    "\n",
    "    def early_stop(self, validation_accuracy):\n",
    "        if validation_accuracy > (self.max_validation_accuracy + self.min_delta):\n",
    "            self.max_validation_accuracy = validation_accuracy\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def train(model, optimizer, dataloader, loss_fn=loss_fn):\n",
    "    running_loss_value = 0\n",
    "    for images, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        running_loss_value += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return running_loss_value / len(dataloader)\n",
    "\n",
    "def test_eval(model, dataloader, loss_fn=loss_fn):\n",
    "    running_loss_value = 0\n",
    "    running_acc_value = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            acc = acc_function(outputs, labels)\n",
    "            running_loss_value += loss.item()\n",
    "            running_acc_value += acc.item()\n",
    "    running_acc_value /= len(dataloader)\n",
    "    running_loss_value /= len(dataloader)\n",
    "    return running_acc_value*100, running_loss_value\n",
    "\n",
    "def train_eval_test(model, train_dataloader, val_dataloader, test_dataloader, no_epochs=10):\n",
    "    es = AccuracyEarlyStopper()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_loss_arr, train_acc_arr, eval_loss_arr, eval_acc_arr = [], [], [], []\n",
    "    for i in range(no_epochs):\n",
    "        train_loss = train(model, optimizer, train_dataloader)\n",
    "        eval_acc, eval_loss = test_eval(model, val_dataloader)\n",
    "        print(f'Epoch {i+1} Train Loss: {train_loss:>8f}, Eval Accuracy: {eval_acc:>0.2f}%, Eval Loss: {eval_loss:>8f}')\n",
    "        train_loss_arr.append(train_loss)\n",
    "        eval_loss_arr.append(eval_loss)\n",
    "        eval_acc_arr.append(eval_acc)\n",
    "#         if es.early_stop(eval_acc):\n",
    "#             print('Early stopping activated')\n",
    "#             break\n",
    "    test_acc, test_loss = test_eval(model, test_dataloader)\n",
    "    print(f\"Test Accuracy: {test_acc}, Test Loss: {test_loss}\")\n",
    "    return train_loss_arr, train_acc_arr, eval_loss_arr, eval_acc_arr, test_acc, test_loss\n",
    "\n",
    "# Function to create a ResNet model and replace convolutions with deformable convolutions\n",
    "def create_deformable_resnet_model():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 102)  # Assuming 102 classes for the Flowers dataset\n",
    "\n",
    "    # Replace certain conv layers with deformable conv layers\n",
    "    model = insert_deformable_convs(model)\n",
    "\n",
    "    # Freeze all layers except deformable convolutions and the final classifier\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"conv1.2\" not in name and \"fc\" not in name:  # conv1.2 is the deformable conv layer\n",
    "            param.requires_grad = False\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "# Main code\n",
    "batch_size = 64\n",
    "no_epochs = 10\n",
    "learning_rate = 0.001\n",
    "train_loader, test_loader, val_loader = get_data_loader(batch_size)\n",
    "\n",
    "# Create and train the deformable ResNet model\n",
    "deformable_resnet_model = create_deformable_resnet_model(size=18)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, deformable_resnet_model.parameters()), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss_arr, train_acc_arr, eval_loss_arr, eval_acc_arr, test_acc, test_loss = train_eval_test(\n",
    "    deformable_resnet_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    no_epochs=no_epochs\n",
    ")\n",
    "\n",
    "# At this point, you can print out the results or save the model\n",
    "print(f\"Test accuracy: {test_acc}, Test loss: {test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
